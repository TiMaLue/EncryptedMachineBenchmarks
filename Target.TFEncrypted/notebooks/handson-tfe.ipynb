{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae18f555",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import onnx\n",
    "import onnx2keras\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c79f7fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.python.framework import graph_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2e741fcb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model_file = \"/bench_data/SimpleLogisticReg/model.onnx\"\n",
    "# model_file = \"/bench_data/image_cls/densenet161.onnx\"\n",
    "model_file = \"/bench_data/SimpleFFNN/model.onnx\"\n",
    "model_onnx = onnx.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6e7d40d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert len(model_onnx.graph.input) == 1\n",
    "\n",
    "input_names = [input_.name for input_ in model_onnx.graph.input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "20d4a032",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "onnx_model = model_onnx\n",
    "\n",
    "for i in range(len(onnx_model.graph.node)):\n",
    "\tfor j in range(len(onnx_model.graph.node[i].input)):\n",
    "\t\tif \":\" in onnx_model.graph.node[i].input[j]:\n",
    "\t\t\tonnx_model.graph.node[i].input[j] = onnx_model.graph.node[i].input[j].replace(\":\", \"_\")\n",
    "\n",
    "\tfor j in range(len(onnx_model.graph.node[i].output)):\n",
    "\t\tif \":\" in onnx_model.graph.node[i].output[j]:\n",
    "\t\t\tonnx_model.graph.node[i].output[j] = onnx_model.graph.node[i].output[j].replace(\":\", \"_\")\n",
    "\n",
    "for i in range(len(onnx_model.graph.input)):\n",
    "\tif \":\" in onnx_model.graph.input[i].name:\n",
    "\t\tonnx_model.graph.input[i].name = onnx_model.graph.input[i].name.replace(\":\", \"_\")\n",
    "\n",
    "for i in range(len(onnx_model.graph.output)):\n",
    "\tif \":\" in  onnx_model.graph.output[i].name:\n",
    "\t\tonnx_model.graph.output[i].name = onnx_model.graph.output[i].name.replace(\":\", \"_\")\n",
    "\n",
    "for i in range(len(onnx_model.graph.initializer)):\n",
    "\tif \":\" in  onnx_model.graph.initializer[i].name:\n",
    "\t\tonnx_model.graph.initializer[i].name = onnx_model.graph.initializer[i].name.replace(\":\", \"_\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "35987a37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ir_version: 7\n",
       "producer_name: \"pytorch\"\n",
       "producer_version: \"1.12.1\"\n",
       "graph {\n",
       "  node {\n",
       "    input: \"onnx__Gemm_0\"\n",
       "    input: \"linear1.weight\"\n",
       "    input: \"linear1.bias\"\n",
       "    output: \"onnx__Relu_7\"\n",
       "    name: \"Gemm_0\"\n",
       "    op_type: \"Gemm\"\n",
       "    attribute {\n",
       "      name: \"alpha\"\n",
       "      f: 1.0\n",
       "      type: FLOAT\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"beta\"\n",
       "      f: 1.0\n",
       "      type: FLOAT\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"transB\"\n",
       "      i: 1\n",
       "      type: INT\n",
       "    }\n",
       "  }\n",
       "  node {\n",
       "    input: \"onnx__Relu_7\"\n",
       "    output: \"onnx__Gemm_8\"\n",
       "    name: \"Relu_1\"\n",
       "    op_type: \"Relu\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"onnx__Gemm_8\"\n",
       "    input: \"linear2.weight\"\n",
       "    input: \"linear2.bias\"\n",
       "    output: \"onnx__Relu_9\"\n",
       "    name: \"Gemm_2\"\n",
       "    op_type: \"Gemm\"\n",
       "    attribute {\n",
       "      name: \"alpha\"\n",
       "      f: 1.0\n",
       "      type: FLOAT\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"beta\"\n",
       "      f: 1.0\n",
       "      type: FLOAT\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"transB\"\n",
       "      i: 1\n",
       "      type: INT\n",
       "    }\n",
       "  }\n",
       "  node {\n",
       "    input: \"onnx__Relu_9\"\n",
       "    output: \"onnx__Gemm_10\"\n",
       "    name: \"Relu_3\"\n",
       "    op_type: \"Relu\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"onnx__Gemm_10\"\n",
       "    input: \"linear3.weight\"\n",
       "    input: \"linear3.bias\"\n",
       "    output: \"onnx__Sigmoid_11\"\n",
       "    name: \"Gemm_4\"\n",
       "    op_type: \"Gemm\"\n",
       "    attribute {\n",
       "      name: \"alpha\"\n",
       "      f: 1.0\n",
       "      type: FLOAT\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"beta\"\n",
       "      f: 1.0\n",
       "      type: FLOAT\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"transB\"\n",
       "      i: 1\n",
       "      type: INT\n",
       "    }\n",
       "  }\n",
       "  node {\n",
       "    input: \"onnx__Sigmoid_11\"\n",
       "    output: \"12\"\n",
       "    name: \"Sigmoid_5\"\n",
       "    op_type: \"Sigmoid\"\n",
       "  }\n",
       "  name: \"torch_jit\"\n",
       "  initializer {\n",
       "    dims: 10\n",
       "    dims: 20\n",
       "    data_type: 1\n",
       "    name: \"linear1.weight\"\n",
       "    raw_data: \"x\\366\\021\\275\\222\\301p=\\366\\200\\260\\271\\375\\212\\205=*W\\270\\276P\\3138\\274\\t\\241\\212>\\034\\354P>E{\\306=8N\\250>\\016Z\\252>p\\313\\220\\276\\203x\\033>`\\203\\243>O|\\016\\275.:\\223\\276}~~=K\\321\\226\\276\\304\\036\\333<\\321`\\325\\274\\033:\\360<\\320\\017\\000\\276x`K>\\311\\030$>]\\236\\333\\275M2\\376=\\031\\031\\037>R\\000\\010<?\\320\\035>1\\233\\246\\276\\377\\301\\265\\276DrH>\\271\\3023\\276\\245q2\\276\\254\\033\\224\\275\\362\\324\\200\\275Y\\266\\004>\\'\\370\\000\\276\\352\\332->l;m=k\\322\\n=\\3534\\311\\275\\251\\236\\364=\\232\\312\\035>\\024\\230,\\274\\336BC>\\203(~=\\321\\231\\031\\276(\\004}\\276\\225\\034G=(\\037\\267\\275\\311p\\371=4\\246H\\276\\300\\346v>\\023z9>V\\325\\244\\275A\\316\\234=o\\251\\201\\276\\376o\\022\\276z\\033\\257<\\226I\\304=\\326t2\\274\\327\\202\\033>\\023k\\272=\\0360Q\\274\\344\\tH\\276\\353\\241Z\\273\\000I\\037\\276\\215Tv=x7\\335=ZA\\206\\276?[\\245\\273-\\204\\010\\277V\\033.\\276)t+=\\274Kq\\274\\303?\\273>\\347\\204g\\2762\\207i\\275F\\2352>\\t\\273I\\275\\021S\\202\\276\\273\\033\\001>\\267=\\021>\\342\\\"o=<\\346\\335\\276F\\3603\\276MQ\\215\\276\\210&t>Rn\\373=\\332\\3178>\\247\\320\\254>y\\207-\\276\\377?C\\275\\356\\201\\273\\275\\253\\022\\037\\276\\346+\\241\\274\\260\\306d>\\250\\\"\\303\\276\\225\\264\\270\\274<\\203a\\275%;\\251>\\277R1\\276C\\211\\014>f\\203\\262\\276[5\\340<2\\247-\\275zF\\205=8\\0012\\276\\256]\\235>\\033?$\\276\\004\\223J\\276\\302\\223\\024\\276\\322\\036L\\276\\'N\\256\\276jIn\\276\\222\\310\\361<\\r\\0063>1\\217\\013\\275&\\263^>\\020#\\225\\275\\276^5<\\207>X\\276\\375%g\\274\\322 \\246>a\\007$\\277\\330\\341\\244\\276\\201\\272\\253\\275\\303N\\235\\275\\251:J\\276H\\242\\321>Z\\314\\377\\276\\265\\371s\\2759\\227\\344\\276\\231\\325v\\276O\\212\\231\\275\\\\\\263$\\277>\\241\\323<\\245s\\250>\\222\\016\\367;,\\0234=\\246\\373\\n=W\\301\\016\\276B\\206\\210\\275$\\313l;5\\216\\222\\276\\230\\013\\222\\276\\350O\\333\\275y8\\225\\276\\2020Q\\274\\314\\302\\027>p\\225\\341\\275\\024\\221\\031\\276\\361\\362h\\276\\304b\\014\\276\\231\\007\\254=\\021_\\344<$_\\002=\\325\\026i=|\\237\\r>rM\\010\\276\\366\\216\\234\\276\\353u\\003>\\263\\225\\000\\276,&\\200\\275\\220\\257\\240\\276{\\301\\334\\275\\316\\005#\\276\\356?\\230=E*N=h\\253\\224>\\303a\\263>k\\315.=9\\362Q\\276f\\363\\271\\274r\\026b\\276H\\360\\241=\\246a\\230>\\256\\234\\302\\276\\261\\004\\270\\275#\\351\\252\\274\\305\\303\\273>\\337Z3\\276\\217*\\247\\276\\252mb>>`\\220\\276\\300\\327k>\\r\\253\\207\\275\\021J\\260=\\205\\334\\226=\\322\\264e=\\212\\325O>\\211\\303\\211\\276\\203\\366!\\276\\260e\\r>\\301Y\\241\\276\\034\\020?\\276|\\277e>$9\\305;G\\307\\361\\276\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 10\n",
       "    data_type: 1\n",
       "    name: \"linear1.bias\"\n",
       "    raw_data: \"\\315\\270&?\\251n\\006?\\206\\331\\256?\\335\\277\\003?\\361S\\200?\\003#\\027\\277\\200\\377\\013\\277\\345o{?>\\214\\221?\\313\\303\\375=\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 5\n",
       "    dims: 10\n",
       "    data_type: 1\n",
       "    name: \"linear2.weight\"\n",
       "    raw_data: \"\\327\\351\\006>\\036\\\"Q\\276\\353_r\\276zH\\301>;\\355\\247:r\\325\\021?\\322\\375\\250\\276J\\352\\366=r\\270s\\276\\305\\r\\214\\274ODN\\2766\\222m>F\\001f\\277\\2425\\030\\277\\302_d?*\\241\\247=\\023y\\243\\277\\353;b?\\262\\215\\265\\276f\\005j\\276\\225\\030\\316\\276\\264A\\212>\\246\\326Y\\276\\275~M=\\034\\315\\342\\276\\261\\n\\224\\275B\\007\\212>\\013\\026@>\\353\\t\\341\\276\\254\\347\\327>8\\302\\376\\276\\226\\230\\360\\276\\320\\002\\021?V\\327\\321>\\022\\233*\\277Z\\217\\004?Y\\351\\177>\\236\\004>\\276\\263K\\223?\\234{\\017\\277by(?-\\365\\317>\\217\\211R\\277#\\\"\\324\\276\\230\\004\\375><\\027\\r\\277\\212\\025\\372\\276Y\\026\\\"?J_\\026\\277[\\275\\345>\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 5\n",
       "    data_type: 1\n",
       "    name: \"linear2.bias\"\n",
       "    raw_data: \"\\250,\\307\\276\\257c\\r?\\233.\\205\\276\\350c\\247?\\246PI>\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 1\n",
       "    dims: 5\n",
       "    data_type: 1\n",
       "    name: \"linear3.weight\"\n",
       "    raw_data: \"\\037\\202P\\277(\\'\\007@\\225\\247V?\\021u\\r\\300\\000\\010\\331?\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 1\n",
       "    data_type: 1\n",
       "    name: \"linear3.bias\"\n",
       "    raw_data: \"AL\\346\\274\"\n",
       "  }\n",
       "  input {\n",
       "    name: \"onnx__Gemm_0\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: 1\n",
       "        shape {\n",
       "          dim {\n",
       "            dim_value: 500\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 20\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  output {\n",
       "    name: \"12\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: 1\n",
       "        shape {\n",
       "          dim {\n",
       "            dim_value: 500\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "opset_import {\n",
       "  version: 13\n",
       "}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5da6d990",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "input_names = [input_.name for input_ in model_onnx.graph.input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8e2d8bd7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['onnx__Gemm_0']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a6726592",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['onnx__Gemm_0']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "10bbc437",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 20)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [input_ for input_ in model_onnx.graph.input]\n",
    "input_shape = tuple(d.dim_value for d in inputs[0].type.tensor_type.shape.dim)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "468164c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06665545, 0.84347326, 0.58189255, ..., 0.437123  , 0.31091574,\n",
       "        0.5021986 ],\n",
       "       [0.429636  , 0.45136368, 0.27877587, ..., 0.05679522, 0.54380655,\n",
       "        0.17073445],\n",
       "       [0.409653  , 0.00577834, 0.6634853 , ..., 0.15607181, 0.09779806,\n",
       "        0.3926815 ],\n",
       "       ...,\n",
       "       [0.17229171, 0.47023144, 0.66485035, ..., 0.6988369 , 0.3616517 ,\n",
       "        0.07267076],\n",
       "       [0.38140118, 0.93936807, 0.8004927 , ..., 0.6854865 , 0.42916557,\n",
       "        0.6992769 ],\n",
       "       [0.37052566, 0.12898919, 0.5311173 , ..., 0.8691879 , 0.58729076,\n",
       "        0.41788802]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.random(input_shape)\n",
    "x = np.float32(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "67f5d212",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_k = onnx2keras.onnx_to_keras(model_onnx, input_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "13522b06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# with tf.compat.v1.Session() as sess:\n",
    "#     pred = model_k.apply(x)\n",
    "#     o = sess.run(pred)\n",
    "#     storage_path = \"LogisticReg1\"\n",
    "#     tf.saved_model.save(model_k, storage_path)\n",
    "# o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d1fe26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.compat.v1.Session() as sess:\n",
    "#     pred = model_k.apply(x)\n",
    "#     sess.run(pred)\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "151b6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_missing_tensor_contents(graph_def):\n",
    "    nodes = graph_def.node\n",
    "    for x in nodes:\n",
    "        name = x.name\n",
    "        dtype = x.attr[\"dtype\"].type\n",
    "        x_shape = [i.size for i in x.attr[\"value\"].tensor.tensor_shape.dim]\n",
    "        has_tensor_content = len(x.attr[\"value\"].tensor.tensor_content) > 0\n",
    "#         print(f\"name={name} \\t\\t dtype={dtype}, x_shape={x_shape} has_tensor_content={has_tensor_content}\")\n",
    "        if len(x_shape) > 0 and not has_tensor_content:\n",
    "            print(f\"Node has shape but no tensor_content: {name}\")\n",
    "            float_vals = x.attr[\"value\"].tensor.float_val\n",
    "            has_floats = len(float_vals) > 0\n",
    "            if not has_floats:\n",
    "                raise RuntimeError(f\"No tensor_content and not float_val: {name}\")\n",
    "            print(f\"Converting float_val to tensor_content: {name}\")\n",
    "            float_vals = np.array(list(float_vals), dtype=\"float32\")\n",
    "            arr = np.ndarray(shape=x_shape, dtype=\"float32\", buffer=float_vals)\n",
    "            tensor_content = numpy_helper.from_array(arr)\n",
    "            x.attr[\"value\"].tensor.tensor_content = tensor_content.raw_data\n",
    "            arr_1 = array.array(\"f\", x.attr[\"value\"].tensor.tensor_content)\n",
    "            arr_1 = np.array(arr_1).reshape(x_shape)\n",
    "            assert arr_1 == arr\n",
    "#             del x.attr[\"value\"].tensor.float_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7528dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_output_node(frozen_graph, current_name):\n",
    "    found = False\n",
    "    for n in frozen_graph.node:\n",
    "        if n.name == current_name:\n",
    "            found = True\n",
    "            break\n",
    "    assert found\n",
    "    n.name = \"ModelOut\"\n",
    "def rename_input_node(frozen_graph, current_name):\n",
    "    found = False\n",
    "    for n in frozen_graph.node:\n",
    "        if n.name == model_input:\n",
    "            assert not found\n",
    "            n.name = \"ModelInput\"\n",
    "            found = True\n",
    "        for i in range(len(n.input)):\n",
    "            if n.input[i] == model_input:\n",
    "                n.input[i] = \"ModelInput\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fd681732",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:onnx2keras:Converter is called.\n",
      "DEBUG:onnx2keras:List input shapes:\n",
      "DEBUG:onnx2keras:None\n",
      "DEBUG:onnx2keras:List inputs:\n",
      "DEBUG:onnx2keras:Input 0 -> onnx__Gemm_0.\n",
      "DEBUG:onnx2keras:List outputs:\n",
      "DEBUG:onnx2keras:Output 0 -> 12.\n",
      "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
      "DEBUG:onnx2keras:Found weight linear1.weight with shape (10, 20).\n",
      "DEBUG:onnx2keras:Found weight linear1.bias with shape (10,).\n",
      "DEBUG:onnx2keras:Found weight linear2.weight with shape (5, 10).\n",
      "DEBUG:onnx2keras:Found weight linear2.bias with shape (5,).\n",
      "DEBUG:onnx2keras:Found weight linear3.weight with shape (1, 5).\n",
      "DEBUG:onnx2keras:Found weight linear3.bias with shape (1,).\n",
      "DEBUG:onnx2keras:Found input onnx__Gemm_0 with shape [20]\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: onnx__Relu_7\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name onnx__Gemm_0).\n",
      "DEBUG:onnx2keras:Check input 1 (name linear1.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name linear1.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 20, output units 10.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"onnx__Relu_7_1/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: onnx__Gemm_8\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name onnx__Relu_7).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"onnx__Gemm_8_1/Relu:0\", shape=(?, 10), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: onnx__Relu_9\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name onnx__Gemm_8).\n",
      "DEBUG:onnx2keras:Check input 1 (name linear2.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name linear2.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 10, output units 5.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"onnx__Relu_9_1/BiasAdd:0\", shape=(?, 5), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Relu\n",
      "DEBUG:onnx2keras:node_name: onnx__Gemm_10\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name onnx__Relu_9).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"onnx__Gemm_10_1/Relu:0\", shape=(?, 5), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Gemm\n",
      "DEBUG:onnx2keras:node_name: onnx__Sigmoid_11\n",
      "DEBUG:onnx2keras:node_params: {'alpha': 1.0, 'beta': 1.0, 'transB': 1, 'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name onnx__Gemm_10).\n",
      "DEBUG:onnx2keras:Check input 1 (name linear3.weight).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:Check input 2 (name linear3.bias).\n",
      "DEBUG:onnx2keras:The input not found in layers / model inputs.\n",
      "DEBUG:onnx2keras:Found in weights, add as a numpy constant.\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:gemm:Convert GEMM with bias.\n",
      "DEBUG:onnx2keras:gemm:Transposing W matrix.\n",
      "DEBUG:onnx2keras:gemm:Input units 5, output units 1.\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"onnx__Sigmoid_11_1/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "DEBUG:onnx2keras:######\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Converting ONNX operation\n",
      "DEBUG:onnx2keras:type: Sigmoid\n",
      "DEBUG:onnx2keras:node_name: 12\n",
      "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': None}\n",
      "DEBUG:onnx2keras:...\n",
      "DEBUG:onnx2keras:Check if all inputs are available:\n",
      "DEBUG:onnx2keras:Check input 0 (name onnx__Sigmoid_11).\n",
      "DEBUG:onnx2keras:... found all, continue\n",
      "DEBUG:onnx2keras:Output TF Layer -> Tensor(\"12_1/Sigmoid:0\", shape=(?, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tf_encrypted/keras/engine/base_layer_utils.py:28: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tf_encrypted/keras/engine/base_layer_utils.py:28: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "TF Encrypted does not yet support the InputLayer layer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/ma5/lib/python3.6/site-packages/tf_encrypted/keras/models/sequential.py\u001b[0m in \u001b[0;36m_instantiate_tfe_layer\u001b[0;34m(keras_layer_config)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mtfe_layer_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras_layer_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tf_encrypted.keras.layers' has no attribute 'InputLayer'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-cf7af0d9d561>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtf_encrypted\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSecureNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtfe_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstorage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LogisticReg1/saved_model-1.pb\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ma5/lib/python3.6/site-packages/tf_encrypted/keras/models/sequential.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0mtfe_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0mtfe_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ma5/lib/python3.6/site-packages/tf_encrypted/keras/models/sequential.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk_l_c\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"layers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mtfe_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_instantiate_tfe_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_l_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mtfe_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfe_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ma5/lib/python3.6/site-packages/tf_encrypted/keras/models/sequential.py\u001b[0m in \u001b[0;36m_instantiate_tfe_layer\u001b[0;34m(keras_layer_config)\u001b[0m\n\u001b[1;32m    276\u001b[0m         raise RuntimeError(\n\u001b[1;32m    277\u001b[0m             \"TF Encrypted does not yet support the {lcls} layer.\".format(\n\u001b[0;32m--> 278\u001b[0;31m                 \u001b[0mlcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras_layer_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m             )\n\u001b[1;32m    280\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: TF Encrypted does not yet support the InputLayer layer."
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    model_k = onnx2keras.onnx_to_keras(model_onnx, input_names, verbose=False)\n",
    "    import tf_encrypted as tfe\n",
    "    with tfe.protocol.SecureNN():\n",
    "        tfe_model = tfe.keras.models.clone_model(model_k)\n",
    "    pred = model_k.apply(x)\n",
    "    storage_path = \"LogisticReg1/saved_model-1.pb\"\n",
    "#     storage_path = \"densenet161/saved_model.pb\"\n",
    "    model_output = model_k.output.name.replace(\":0\", \"\")\n",
    "    model_input = model_k.input.name.replace(\":0\", \"\")\n",
    "    constant_graph = graph_util.convert_variables_to_constants(\n",
    "        sess, sess.graph.as_graph_def(), [model_output]\n",
    "    )\n",
    "    frozen_graph = graph_util.remove_training_nodes(constant_graph)\n",
    "    fix_missing_tensor_contents(frozen_graph)\n",
    "    rename_output_node(frozen_graph, model_output)\n",
    "    rename_input_node(frozen_graph, model_input)\n",
    "    with open(storage_path, \"wb\") as f:\n",
    "        f.write(frozen_graph.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "857166fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf_encrypted:Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.5.so'\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Error while reading resource variable onnx__Sigmoid_11_3/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/onnx__Sigmoid_11_3/kernel/N10tensorflow3VarE does not exist.\n\t [[node onnx__Sigmoid_11_3/kernel/Read/ReadVariableOp (defined at /home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'onnx__Sigmoid_11_3/kernel/Read/ReadVariableOp':\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-114-143219021a42>\", line 2, in <module>\n    model_k = onnx2keras.onnx_to_keras(model_onnx, input_names, verbose=False)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/onnx2keras/converter.py\", line 181, in onnx_to_keras\n    keras_names\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/onnx2keras/linear_layers.py\", line 47, in convert_gemm\n    layers[node_name] = dense(layers[node.input[0]])\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 824, in __call__\n    self._maybe_build(inputs)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2146, in _maybe_build\n    self.build(input_shapes)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/core.py\", line 1021, in build\n    trainable=True)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 529, in add_weight\n    aggregation=aggregation)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py\", line 712, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\", line 139, in make_variable\n    shape=variable_shape if variable_shape else None)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 258, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 219, in _variable_v1_call\n    shape=shape)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 197, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 2503, in default_variable_creator\n    shape=shape)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 262, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 1406, in __init__\n    distribute_strategy=distribute_strategy)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 1587, in _init_from_args\n    value = gen_resource_variable_ops.read_variable_op(handle, dtype)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_resource_variable_ops.py\", line 587, in read_variable_op\n    \"ReadVariableOp\", resource=resource, dtype=dtype, name=name)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Error while reading resource variable onnx__Sigmoid_11_3/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/onnx__Sigmoid_11_3/kernel/N10tensorflow3VarE does not exist.\n\t [[{{node onnx__Sigmoid_11_3/kernel/Read/ReadVariableOp}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-e5c04110034d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSecureNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtfe_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/ma5/lib/python3.6/site-packages/tf_encrypted/keras/models/sequential.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0mtfe_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mget_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mget_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \"\"\"\n\u001b[1;32m   1351\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_updates_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m   3183\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3184\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3185\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3186\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3187\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Error while reading resource variable onnx__Sigmoid_11_3/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/onnx__Sigmoid_11_3/kernel/N10tensorflow3VarE does not exist.\n\t [[node onnx__Sigmoid_11_3/kernel/Read/ReadVariableOp (defined at /home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'onnx__Sigmoid_11_3/kernel/Read/ReadVariableOp':\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/asyncio/base_events.py\", line 442, in run_forever\n    self._run_once()\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/asyncio/base_events.py\", line 1462, in _run_once\n    handle._run()\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tornado/gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-114-143219021a42>\", line 2, in <module>\n    model_k = onnx2keras.onnx_to_keras(model_onnx, input_names, verbose=False)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/onnx2keras/converter.py\", line 181, in onnx_to_keras\n    keras_names\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/onnx2keras/linear_layers.py\", line 47, in convert_gemm\n    layers[node_name] = dense(layers[node.input[0]])\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 824, in __call__\n    self._maybe_build(inputs)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 2146, in _maybe_build\n    self.build(input_shapes)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/core.py\", line 1021, in build\n    trainable=True)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 529, in add_weight\n    aggregation=aggregation)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py\", line 712, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\", line 139, in make_variable\n    shape=variable_shape if variable_shape else None)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 258, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 219, in _variable_v1_call\n    shape=shape)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 197, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 2503, in default_variable_creator\n    shape=shape)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py\", line 262, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 1406, in __init__\n    distribute_strategy=distribute_strategy)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 1587, in _init_from_args\n    value = gen_resource_variable_ops.read_variable_op(handle, dtype)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_resource_variable_ops.py\", line 587, in read_variable_op\n    \"ReadVariableOp\", resource=resource, dtype=dtype, name=name)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/home/amin/miniconda3/envs/ma5/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "20400740",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node {\n",
       "  name: \"ModelInput\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "        dim {\n",
       "          size: -1\n",
       "        }\n",
       "        dim {\n",
       "          size: 20\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Relu_7_3/kernel\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_FLOAT\n",
       "        tensor_shape {\n",
       "          dim {\n",
       "            size: 20\n",
       "          }\n",
       "          dim {\n",
       "            size: 10\n",
       "          }\n",
       "        }\n",
       "        tensor_content: \"x\\366\\021\\275\\033:\\360<k\\322\\n=\\226I\\304=\\t\\273I\\275<\\203a\\275\\020#\\225\\275,\\0234=rM\\010\\276#\\351\\252\\274\\222\\301p=\\320\\017\\000\\276\\3534\\311\\275\\326t2\\274\\021S\\202\\276%;\\251>\\276^5<\\246\\373\\n=\\366\\216\\234\\276\\305\\303\\273>\\366\\200\\260\\271x`K>\\251\\236\\364=\\327\\202\\033>\\273\\033\\001>\\277R1\\276\\207>X\\276W\\301\\016\\276\\353u\\003>\\337Z3\\276\\375\\212\\205=\\311\\030$>\\232\\312\\035>\\023k\\272=\\267=\\021>C\\211\\014>\\375%g\\274B\\206\\210\\275\\263\\225\\000\\276\\217*\\247\\276*W\\270\\276]\\236\\333\\275\\024\\230,\\274\\0360Q\\274\\342\\\"o=f\\203\\262\\276\\322 \\246>$\\313l;,&\\200\\275\\252mb>P\\3138\\274M2\\376=\\336BC>\\344\\tH\\276<\\346\\335\\276[5\\340<a\\007$\\2775\\216\\222\\276\\220\\257\\240\\276>`\\220\\276\\t\\241\\212>\\031\\031\\037>\\203(~=\\353\\241Z\\273F\\3603\\2762\\247-\\275\\330\\341\\244\\276\\230\\013\\222\\276{\\301\\334\\275\\300\\327k>\\034\\354P>R\\000\\010<\\321\\231\\031\\276\\000I\\037\\276MQ\\215\\276zF\\205=\\201\\272\\253\\275\\350O\\333\\275\\316\\005#\\276\\r\\253\\207\\275E{\\306=?\\320\\035>(\\004}\\276\\215Tv=\\210&t>8\\0012\\276\\303N\\235\\275y8\\225\\276\\356?\\230=\\021J\\260=8N\\250>1\\233\\246\\276\\225\\034G=x7\\335=Rn\\373=\\256]\\235>\\251:J\\276\\2020Q\\274E*N=\\205\\334\\226=\\016Z\\252>\\377\\301\\265\\276(\\037\\267\\275ZA\\206\\276\\332\\3178>\\033?$\\276H\\242\\321>\\314\\302\\027>h\\253\\224>\\322\\264e=p\\313\\220\\276DrH>\\311p\\371=?[\\245\\273\\247\\320\\254>\\004\\223J\\276Z\\314\\377\\276p\\225\\341\\275\\303a\\263>\\212\\325O>\\203x\\033>\\271\\3023\\2764\\246H\\276-\\204\\010\\277y\\207-\\276\\302\\223\\024\\276\\265\\371s\\275\\024\\221\\031\\276k\\315.=\\211\\303\\211\\276`\\203\\243>\\245q2\\276\\300\\346v>V\\033.\\276\\377?C\\275\\322\\036L\\2769\\227\\344\\276\\361\\362h\\2769\\362Q\\276\\203\\366!\\276O|\\016\\275\\254\\033\\224\\275\\023z9>)t+=\\356\\201\\273\\275\\'N\\256\\276\\231\\325v\\276\\304b\\014\\276f\\363\\271\\274\\260e\\r>.:\\223\\276\\362\\324\\200\\275V\\325\\244\\275\\274Kq\\274\\253\\022\\037\\276jIn\\276O\\212\\231\\275\\231\\007\\254=r\\026b\\276\\301Y\\241\\276}~~=Y\\266\\004>A\\316\\234=\\303?\\273>\\346+\\241\\274\\222\\310\\361<\\\\\\263$\\277\\021_\\344<H\\360\\241=\\034\\020?\\276K\\321\\226\\276\\'\\370\\000\\276o\\251\\201\\276\\347\\204g\\276\\260\\306d>\\r\\0063>>\\241\\323<$_\\002=\\246a\\230>|\\277e>\\304\\036\\333<\\352\\332->\\376o\\022\\2762\\207i\\275\\250\\\"\\303\\2761\\217\\013\\275\\245s\\250>\\325\\026i=\\256\\234\\302\\276$9\\305;\\321`\\325\\274l;m=z\\033\\257<F\\2352>\\225\\264\\270\\274&\\263^>\\222\\016\\367;|\\237\\r>\\261\\004\\270\\275G\\307\\361\\276\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Relu_7_3/bias\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_FLOAT\n",
       "        tensor_shape {\n",
       "          dim {\n",
       "            size: 10\n",
       "          }\n",
       "        }\n",
       "        tensor_content: \"\\315\\270&?\\251n\\006?\\206\\331\\256?\\335\\277\\003?\\361S\\200?\\003#\\027\\277\\200\\377\\013\\277\\345o{?>\\214\\221?\\313\\303\\375=\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Relu_7_3/MatMul\"\n",
       "  op: \"MatMul\"\n",
       "  input: \"ModelInput\"\n",
       "  input: \"onnx__Relu_7_3/kernel\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"transpose_a\"\n",
       "    value {\n",
       "      b: false\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"transpose_b\"\n",
       "    value {\n",
       "      b: false\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Relu_7_3/BiasAdd\"\n",
       "  op: \"BiasAdd\"\n",
       "  input: \"onnx__Relu_7_3/MatMul\"\n",
       "  input: \"onnx__Relu_7_3/bias\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"data_format\"\n",
       "    value {\n",
       "      s: \"NHWC\"\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Gemm_8_3/Relu\"\n",
       "  op: \"Relu\"\n",
       "  input: \"onnx__Relu_7_3/BiasAdd\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Relu_9_3/kernel\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_FLOAT\n",
       "        tensor_shape {\n",
       "          dim {\n",
       "            size: 10\n",
       "          }\n",
       "          dim {\n",
       "            size: 5\n",
       "          }\n",
       "        }\n",
       "        tensor_content: \"\\327\\351\\006>ODN\\276\\225\\030\\316\\2768\\302\\376\\276by(?\\036\\\"Q\\2766\\222m>\\264A\\212>\\226\\230\\360\\276-\\365\\317>\\353_r\\276F\\001f\\277\\246\\326Y\\276\\320\\002\\021?\\217\\211R\\277zH\\301>\\2425\\030\\277\\275~M=V\\327\\321>#\\\"\\324\\276;\\355\\247:\\302_d?\\034\\315\\342\\276\\022\\233*\\277\\230\\004\\375>r\\325\\021?*\\241\\247=\\261\\n\\224\\275Z\\217\\004?<\\027\\r\\277\\322\\375\\250\\276\\023y\\243\\277B\\007\\212>Y\\351\\177>\\212\\025\\372\\276J\\352\\366=\\353;b?\\013\\026@>\\236\\004>\\276Y\\026\\\"?r\\270s\\276\\262\\215\\265\\276\\353\\t\\341\\276\\263K\\223?J_\\026\\277\\305\\r\\214\\274f\\005j\\276\\254\\347\\327>\\234{\\017\\277[\\275\\345>\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Relu_9_3/bias\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_FLOAT\n",
       "        tensor_shape {\n",
       "          dim {\n",
       "            size: 5\n",
       "          }\n",
       "        }\n",
       "        tensor_content: \"\\250,\\307\\276\\257c\\r?\\233.\\205\\276\\350c\\247?\\246PI>\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Relu_9_3/MatMul\"\n",
       "  op: \"MatMul\"\n",
       "  input: \"onnx__Gemm_8_3/Relu\"\n",
       "  input: \"onnx__Relu_9_3/kernel\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"transpose_a\"\n",
       "    value {\n",
       "      b: false\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"transpose_b\"\n",
       "    value {\n",
       "      b: false\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Relu_9_3/BiasAdd\"\n",
       "  op: \"BiasAdd\"\n",
       "  input: \"onnx__Relu_9_3/MatMul\"\n",
       "  input: \"onnx__Relu_9_3/bias\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"data_format\"\n",
       "    value {\n",
       "      s: \"NHWC\"\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Gemm_10_3/Relu\"\n",
       "  op: \"Relu\"\n",
       "  input: \"onnx__Relu_9_3/BiasAdd\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Sigmoid_11_3/kernel\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_FLOAT\n",
       "        tensor_shape {\n",
       "          dim {\n",
       "            size: 5\n",
       "          }\n",
       "          dim {\n",
       "            size: 1\n",
       "          }\n",
       "        }\n",
       "        tensor_content: \"\\037\\202P\\277(\\'\\007@\\225\\247V?\\021u\\r\\300\\000\\010\\331?\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Sigmoid_11_3/bias\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_FLOAT\n",
       "        tensor_shape {\n",
       "          dim {\n",
       "            size: 1\n",
       "          }\n",
       "        }\n",
       "        tensor_content: \"AL\\346\\274\"\n",
       "        float_val: -0.028112532570958138\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Sigmoid_11_3/MatMul\"\n",
       "  op: \"MatMul\"\n",
       "  input: \"onnx__Gemm_10_3/Relu\"\n",
       "  input: \"onnx__Sigmoid_11_3/kernel\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"transpose_a\"\n",
       "    value {\n",
       "      b: false\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"transpose_b\"\n",
       "    value {\n",
       "      b: false\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Sigmoid_11_3/BiasAdd\"\n",
       "  op: \"BiasAdd\"\n",
       "  input: \"onnx__Sigmoid_11_3/MatMul\"\n",
       "  input: \"onnx__Sigmoid_11_3/bias\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"data_format\"\n",
       "    value {\n",
       "      s: \"NHWC\"\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"ModelOut\"\n",
       "  op: \"Sigmoid\"\n",
       "  input: \"onnx__Sigmoid_11_3/BiasAdd\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9156234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = model_k.input.name.replace(\":0\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "667ac30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'onnx__Gemm_0_18'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4dd63427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "node {\n",
       "  name: \"ModelInput\"\n",
       "  op: \"Placeholder\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"shape\"\n",
       "    value {\n",
       "      shape {\n",
       "        dim {\n",
       "          size: -1\n",
       "        }\n",
       "        dim {\n",
       "          size: 20\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Relu_7_1/kernel\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_FLOAT\n",
       "        tensor_shape {\n",
       "          dim {\n",
       "            size: 20\n",
       "          }\n",
       "          dim {\n",
       "            size: 10\n",
       "          }\n",
       "        }\n",
       "        tensor_content: \"x\\366\\021\\275\\033:\\360<k\\322\\n=\\226I\\304=\\t\\273I\\275<\\203a\\275\\020#\\225\\275,\\0234=rM\\010\\276#\\351\\252\\274\\222\\301p=\\320\\017\\000\\276\\3534\\311\\275\\326t2\\274\\021S\\202\\276%;\\251>\\276^5<\\246\\373\\n=\\366\\216\\234\\276\\305\\303\\273>\\366\\200\\260\\271x`K>\\251\\236\\364=\\327\\202\\033>\\273\\033\\001>\\277R1\\276\\207>X\\276W\\301\\016\\276\\353u\\003>\\337Z3\\276\\375\\212\\205=\\311\\030$>\\232\\312\\035>\\023k\\272=\\267=\\021>C\\211\\014>\\375%g\\274B\\206\\210\\275\\263\\225\\000\\276\\217*\\247\\276*W\\270\\276]\\236\\333\\275\\024\\230,\\274\\0360Q\\274\\342\\\"o=f\\203\\262\\276\\322 \\246>$\\313l;,&\\200\\275\\252mb>P\\3138\\274M2\\376=\\336BC>\\344\\tH\\276<\\346\\335\\276[5\\340<a\\007$\\2775\\216\\222\\276\\220\\257\\240\\276>`\\220\\276\\t\\241\\212>\\031\\031\\037>\\203(~=\\353\\241Z\\273F\\3603\\2762\\247-\\275\\330\\341\\244\\276\\230\\013\\222\\276{\\301\\334\\275\\300\\327k>\\034\\354P>R\\000\\010<\\321\\231\\031\\276\\000I\\037\\276MQ\\215\\276zF\\205=\\201\\272\\253\\275\\350O\\333\\275\\316\\005#\\276\\r\\253\\207\\275E{\\306=?\\320\\035>(\\004}\\276\\215Tv=\\210&t>8\\0012\\276\\303N\\235\\275y8\\225\\276\\356?\\230=\\021J\\260=8N\\250>1\\233\\246\\276\\225\\034G=x7\\335=Rn\\373=\\256]\\235>\\251:J\\276\\2020Q\\274E*N=\\205\\334\\226=\\016Z\\252>\\377\\301\\265\\276(\\037\\267\\275ZA\\206\\276\\332\\3178>\\033?$\\276H\\242\\321>\\314\\302\\027>h\\253\\224>\\322\\264e=p\\313\\220\\276DrH>\\311p\\371=?[\\245\\273\\247\\320\\254>\\004\\223J\\276Z\\314\\377\\276p\\225\\341\\275\\303a\\263>\\212\\325O>\\203x\\033>\\271\\3023\\2764\\246H\\276-\\204\\010\\277y\\207-\\276\\302\\223\\024\\276\\265\\371s\\275\\024\\221\\031\\276k\\315.=\\211\\303\\211\\276`\\203\\243>\\245q2\\276\\300\\346v>V\\033.\\276\\377?C\\275\\322\\036L\\2769\\227\\344\\276\\361\\362h\\2769\\362Q\\276\\203\\366!\\276O|\\016\\275\\254\\033\\224\\275\\023z9>)t+=\\356\\201\\273\\275\\'N\\256\\276\\231\\325v\\276\\304b\\014\\276f\\363\\271\\274\\260e\\r>.:\\223\\276\\362\\324\\200\\275V\\325\\244\\275\\274Kq\\274\\253\\022\\037\\276jIn\\276O\\212\\231\\275\\231\\007\\254=r\\026b\\276\\301Y\\241\\276}~~=Y\\266\\004>A\\316\\234=\\303?\\273>\\346+\\241\\274\\222\\310\\361<\\\\\\263$\\277\\021_\\344<H\\360\\241=\\034\\020?\\276K\\321\\226\\276\\'\\370\\000\\276o\\251\\201\\276\\347\\204g\\276\\260\\306d>\\r\\0063>>\\241\\323<$_\\002=\\246a\\230>|\\277e>\\304\\036\\333<\\352\\332->\\376o\\022\\2762\\207i\\275\\250\\\"\\303\\2761\\217\\013\\275\\245s\\250>\\325\\026i=\\256\\234\\302\\276$9\\305;\\321`\\325\\274l;m=z\\033\\257<F\\2352>\\225\\264\\270\\274&\\263^>\\222\\016\\367;|\\237\\r>\\261\\004\\270\\275G\\307\\361\\276\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Relu_7_1/bias\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_FLOAT\n",
       "        tensor_shape {\n",
       "          dim {\n",
       "            size: 10\n",
       "          }\n",
       "        }\n",
       "        tensor_content: \"\\315\\270&?\\251n\\006?\\206\\331\\256?\\335\\277\\003?\\361S\\200?\\003#\\027\\277\\200\\377\\013\\277\\345o{?>\\214\\221?\\313\\303\\375=\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Relu_7_1/MatMul\"\n",
       "  op: \"MatMul\"\n",
       "  input: \"ModelInput\"\n",
       "  input: \"onnx__Relu_7_1/kernel\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"transpose_a\"\n",
       "    value {\n",
       "      b: false\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"transpose_b\"\n",
       "    value {\n",
       "      b: false\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Relu_7_1/BiasAdd\"\n",
       "  op: \"BiasAdd\"\n",
       "  input: \"onnx__Relu_7_1/MatMul\"\n",
       "  input: \"onnx__Relu_7_1/bias\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"data_format\"\n",
       "    value {\n",
       "      s: \"NHWC\"\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Gemm_8_1/Relu\"\n",
       "  op: \"Relu\"\n",
       "  input: \"onnx__Relu_7_1/BiasAdd\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Relu_9_1/kernel\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_FLOAT\n",
       "        tensor_shape {\n",
       "          dim {\n",
       "            size: 10\n",
       "          }\n",
       "          dim {\n",
       "            size: 5\n",
       "          }\n",
       "        }\n",
       "        tensor_content: \"\\327\\351\\006>ODN\\276\\225\\030\\316\\2768\\302\\376\\276by(?\\036\\\"Q\\2766\\222m>\\264A\\212>\\226\\230\\360\\276-\\365\\317>\\353_r\\276F\\001f\\277\\246\\326Y\\276\\320\\002\\021?\\217\\211R\\277zH\\301>\\2425\\030\\277\\275~M=V\\327\\321>#\\\"\\324\\276;\\355\\247:\\302_d?\\034\\315\\342\\276\\022\\233*\\277\\230\\004\\375>r\\325\\021?*\\241\\247=\\261\\n\\224\\275Z\\217\\004?<\\027\\r\\277\\322\\375\\250\\276\\023y\\243\\277B\\007\\212>Y\\351\\177>\\212\\025\\372\\276J\\352\\366=\\353;b?\\013\\026@>\\236\\004>\\276Y\\026\\\"?r\\270s\\276\\262\\215\\265\\276\\353\\t\\341\\276\\263K\\223?J_\\026\\277\\305\\r\\214\\274f\\005j\\276\\254\\347\\327>\\234{\\017\\277[\\275\\345>\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Relu_9_1/bias\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_FLOAT\n",
       "        tensor_shape {\n",
       "          dim {\n",
       "            size: 5\n",
       "          }\n",
       "        }\n",
       "        tensor_content: \"\\250,\\307\\276\\257c\\r?\\233.\\205\\276\\350c\\247?\\246PI>\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Relu_9_1/MatMul\"\n",
       "  op: \"MatMul\"\n",
       "  input: \"onnx__Gemm_8_1/Relu\"\n",
       "  input: \"onnx__Relu_9_1/kernel\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"transpose_a\"\n",
       "    value {\n",
       "      b: false\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"transpose_b\"\n",
       "    value {\n",
       "      b: false\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Relu_9_1/BiasAdd\"\n",
       "  op: \"BiasAdd\"\n",
       "  input: \"onnx__Relu_9_1/MatMul\"\n",
       "  input: \"onnx__Relu_9_1/bias\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"data_format\"\n",
       "    value {\n",
       "      s: \"NHWC\"\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Gemm_10_1/Relu\"\n",
       "  op: \"Relu\"\n",
       "  input: \"onnx__Relu_9_1/BiasAdd\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Sigmoid_11_1/kernel\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_FLOAT\n",
       "        tensor_shape {\n",
       "          dim {\n",
       "            size: 5\n",
       "          }\n",
       "          dim {\n",
       "            size: 1\n",
       "          }\n",
       "        }\n",
       "        tensor_content: \"\\037\\202P\\277(\\'\\007@\\225\\247V?\\021u\\r\\300\\000\\010\\331?\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Sigmoid_11_1/bias\"\n",
       "  op: \"Const\"\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "      tensor {\n",
       "        dtype: DT_FLOAT\n",
       "        tensor_shape {\n",
       "          dim {\n",
       "            size: 1\n",
       "          }\n",
       "        }\n",
       "        tensor_content: \"AL\\346\\274\"\n",
       "        float_val: -0.028112532570958138\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Sigmoid_11_1/MatMul\"\n",
       "  op: \"MatMul\"\n",
       "  input: \"onnx__Gemm_10_1/Relu\"\n",
       "  input: \"onnx__Sigmoid_11_1/kernel\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"transpose_a\"\n",
       "    value {\n",
       "      b: false\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"transpose_b\"\n",
       "    value {\n",
       "      b: false\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"onnx__Sigmoid_11_1/BiasAdd\"\n",
       "  op: \"BiasAdd\"\n",
       "  input: \"onnx__Sigmoid_11_1/MatMul\"\n",
       "  input: \"onnx__Sigmoid_11_1/bias\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"data_format\"\n",
       "    value {\n",
       "      s: \"NHWC\"\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}\n",
       "node {\n",
       "  name: \"ModelOut\"\n",
       "  op: \"Sigmoid\"\n",
       "  input: \"onnx__Sigmoid_11_1/BiasAdd\"\n",
       "  attr {\n",
       "    key: \"T\"\n",
       "    value {\n",
       "      type: DT_FLOAT\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"dtype\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "  attr {\n",
       "    key: \"value\"\n",
       "    value {\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found = False\n",
    "for n in frozen_graph.node:\n",
    "    if n.name == model_input:\n",
    "        assert not found\n",
    "        n.name = \"ModelInput\"\n",
    "        found = True\n",
    "    for i in range(len(n.input)):\n",
    "        if n.input[i] == model_input:\n",
    "            n.input[i] = \"ModelInput\"\n",
    "frozen_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "772dafc7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx__Gemm_0\n",
      "[None, 2]\n",
      "onnx__Sigmoid_3\n",
      "[None, 1]\n",
      "4\n",
      "[None, 1]\n"
     ]
    }
   ],
   "source": [
    "for layer in model_k.layers:\n",
    "    print(layer.name)\n",
    "    print(layer.get_output_at(0).get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5fbca90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "onnx__Gemm_0 (InputLayer)    [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "onnx__Sigmoid_3 (Dense)      (None, 1)                 3         \n",
      "_________________________________________________________________\n",
      "4 (Activation)               (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_k.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4599d0ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "732c4a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x1c\\xb3y\\xbf'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_content.raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f3e4664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e073fac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('f', [-0.9753892421722412])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.array(\"f\", tensor_content.raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8275010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "38d46dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3677117 , 0.13842357, 0.83730658],\n",
       "       [0.7248403 , 0.45039734, 0.6488238 ]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cf916f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36771169514945035"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0a465a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0][0] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "324fb602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.13842357, 0.83730658],\n",
       "       [0.7248403 , 0.45039734, 0.6488238 ]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a3839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
